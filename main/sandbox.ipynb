{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91a3ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def tune_ridge_over_feature_sets(\n",
    "    X_train_scaled,\n",
    "    y_train,\n",
    "    feature_sets,\n",
    "    cv,\n",
    "    scoring,\n",
    "    alpha_grid=None,\n",
    "    random_state=42\n",
    "):\n",
    "    \"\"\"\n",
    "    Tune Ridge regression over multiple feature sets using GridSearchCV.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X_train_scaled : pd.DataFrame\n",
    "        Scaled training features (all features).\n",
    "    y_train : pd.Series or np.ndarray\n",
    "        Target variable for training.\n",
    "    feature_sets : dict\n",
    "        Dictionary mapping feature set names to lists of column names.\n",
    "    cv : cross-validation splitter\n",
    "        e.g., KFold instance.\n",
    "    scoring : dict\n",
    "        Scoring dictionary for GridSearchCV (e.g., r2, rmse, mae).\n",
    "    alpha_grid : list or None\n",
    "        List of alpha values to test. Defaults to [0.1, 1.0, 10.0, 100.0].\n",
    "    random_state : int\n",
    "        Random state for reproducibility.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    results_df : pd.DataFrame\n",
    "        Cross-validated performance for each feature set.\n",
    "    best_row : pd.Series\n",
    "        Row corresponding to the best-performing Ridge model (by RÂ²).\n",
    "    best_model_name : str\n",
    "        Human-readable name of the best Ridge model.\n",
    "    \"\"\"\n",
    "\n",
    "    if alpha_grid is None:\n",
    "        alpha_grid = [0.1, 1.0, 10.0, 100.0]\n",
    "\n",
    "    ridge_param_grid = {\n",
    "        \"alpha\": alpha_grid,\n",
    "        \"fit_intercept\": [True, False]\n",
    "    }\n",
    "\n",
    "    ridge_results = []\n",
    "\n",
    "    for set_name, features in feature_sets.items():\n",
    "        X_loop = X_train_scaled[features]\n",
    "\n",
    "        grid_ridge = GridSearchCV(\n",
    "            estimator=Ridge(random_state=random_state),\n",
    "            param_grid=ridge_param_grid,\n",
    "            cv=cv,\n",
    "            scoring=scoring,\n",
    "            refit=\"r2\"\n",
    "        )\n",
    "\n",
    "        grid_ridge.fit(X_loop, y_train)\n",
    "        best_idx = grid_ridge.best_index_\n",
    "\n",
    "        ridge_results.append({\n",
    "            \"Feature Set\": set_name,\n",
    "            \"Alpha\": grid_ridge.best_params_[\"alpha\"],\n",
    "            \"r2\": grid_ridge.cv_results_[\"mean_test_r2\"][best_idx],\n",
    "            \"rmse\": abs(grid_ridge.cv_results_[\"mean_test_rmse\"][best_idx]),\n",
    "            \"mae\": abs(grid_ridge.cv_results_[\"mean_test_mae\"][best_idx])\n",
    "        })\n",
    "\n",
    "    results_df = pd.DataFrame(ridge_results)\n",
    "    best_row = results_df.sort_values(\"r2\", ascending=False).iloc[0]\n",
    "\n",
    "    best_model_name = f'Ridge (alpha={best_row[\"Alpha\"]})'\n",
    "\n",
    "    return results_df, best_row, best_model_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621ecf91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_ridge(\n",
    "    X_train_scaled,\n",
    "    y_train,\n",
    "    feature_set=feature_set,\n",
    "    cv=kf,\n",
    "    scoring=scoring,\n",
    "    alpha_grid=None,\n",
    "    random_state=42\n",
    "):\n",
    "    # setup parameter grid for Ridge\n",
    "    if alpha_grid is None:\n",
    "        ridge_param_grid = {\n",
    "            \"alpha\": [0.1, 1.0, 10.0, 100.0],\n",
    "            \"fit_intercept\": [True, False]\n",
    "        }\n",
    "\n",
    "    ridge_feat_results = []\n",
    "\n",
    "    for set_name, features in feature_set.items():\n",
    "        loop_X = X_train_scaled[features]\n",
    "\n",
    "        grid_ridge = GridSearchCV(\n",
    "            Ridge(random_state=random_state),\n",
    "            param_grid=ridge_param_grid,\n",
    "            cv=cv,\n",
    "            scoring=scoring,\n",
    "            refit='r2'\n",
    "        )\n",
    "\n",
    "        grid_ridge.fit(loop_X, y_train)\n",
    "        best_index = grid_ridge.best_index_\n",
    "\n",
    "        ridge_feat_results.append({\n",
    "            \"Feature Set\": set_name,\n",
    "            \"Alpha\": grid_ridge.best_params_['alpha'],\n",
    "            \"r2\": grid_ridge.cv_results_['mean_test_r2'][best_index],\n",
    "            \"rmse\": abs(grid_ridge.cv_results_['mean_test_rmse'][best_index]),\n",
    "            \"mae\": abs(grid_ridge.cv_results_['mean_test_mae'][best_index]),\n",
    "        })\n",
    "\n",
    "    ridge_feat_df = pd.DataFrame(ridge_feat_results)\n",
    "    best_row = ridge_feat_df.sort_values(\"r2\", ascending=False).iloc[0]\n",
    "\n",
    "    best_model_name = f'Ridge (alpha={best_row[\"Alpha\"]})'\n",
    "\n",
    "    return ridge_feat_df, best_row, best_model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f01b48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_feat_df, best_ridge_row, best_ridge_name = tune_ridge(\n",
    "    X_train_scaled=X_train_opt_scaled,\n",
    "    y_train=y_train_opt,\n",
    "    feature_sets=feature_set,\n",
    "    cv=kf,\n",
    "    scoring=scoring\n",
    ")\n",
    "\n",
    "ridge_feat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f8a0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find and track the best Ridge performer\n",
    "best_ridge_row = ridge_feat_df.sort_values(\"r2\", ascending=False).iloc[0]\n",
    "\n",
    "best_scores_opt.append({\n",
    "    \"Model\": best_ridge_name,\n",
    "    \"Feature_set\": best_ridge_row[\"Feature Set\"],\n",
    "    \"r2\": best_ridge_row[\"r2\"],\n",
    "    \"rmse\": best_ridge_row[\"rmse\"],\n",
    "    \"mae\": best_ridge_row[\"mae\"]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f59ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_simple_linear(\n",
    "    X_train_scaled,\n",
    "    y_train,\n",
    "    cv=5,\n",
    "    scoring=scoring\n",
    "):\n",
    "    \"\"\"\n",
    "    Tune Simple Linear Regression by testing all single features.\n",
    "    \"\"\"\n",
    "\n",
    "    simple_results = []\n",
    "\n",
    "    for col in X_train_scaled.columns:\n",
    "        X_col = X_train_scaled[[col]]\n",
    "        model = LinearRegression()\n",
    "\n",
    "        scores = cross_validate(\n",
    "            model,\n",
    "            X_col,\n",
    "            y_train,\n",
    "            cv=cv,\n",
    "            scoring=scoring\n",
    "        )\n",
    "\n",
    "        simple_results.append({\n",
    "            \"Feature\": col,\n",
    "            \"r2\": scores[\"test_r2\"].mean(),\n",
    "            \"rmse\": abs(scores[\"test_rmse\"].mean()),\n",
    "            \"mae\": abs(scores[\"test_mae\"].mean())\n",
    "        })\n",
    "\n",
    "    results_df = pd.DataFrame(simple_results)\n",
    "    best_row = results_df.sort_values(\"r2\", ascending=False).iloc[0]\n",
    "    best_model_name = f\"Simple Linear ({best_row['Feature']})\"\n",
    "\n",
    "    return results_df, best_row, best_model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9271e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the Simple Linear entry\n",
    "best_simple_entry = next(\n",
    "    item for item in best_scores_opt\n",
    "    if item[\"Model\"].startswith(\"Simple Linear\")\n",
    ")\n",
    "\n",
    "best_feature = best_simple_entry[\"Feature_set\"]\n",
    "\n",
    "# initialise best simple regression model\n",
    "model_simple_best = LinearRegression(fit_intercept=True)\n",
    "model_simple_best.fit(\n",
    "    X_train_opt_scaled[[best_feature]],\n",
    "    y_train_opt\n",
    ")\n",
    "\n",
    "# add to model dictionary\n",
    "best_models_dict[\"Simple Linear Regression\"] = {\n",
    "    \"model_obj\": model_simple_best,\n",
    "    \"features\": [best_feature]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbdb0267",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(best_models_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661d0f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_multi_linear(\n",
    "    X_train_scaled,\n",
    "    y_train,\n",
    "    feature_set=feature_set,\n",
    "    cv=kf,\n",
    "    scoring=scoring\n",
    "):\n",
    "    \"\"\"\n",
    "    Tune Multiple Linear Regression over feature sets.\n",
    "    \"\"\"\n",
    "\n",
    "    param_grid = {\n",
    "        \"fit_intercept\": [True, False]\n",
    "    }\n",
    "\n",
    "    multi_feat_results = []\n",
    "\n",
    "    for set_name, features in feature_set.items():\n",
    "        loop_X = X_train_scaled[features]\n",
    "\n",
    "        grid_multi = GridSearchCV(\n",
    "            LinearRegression(),\n",
    "            param_grid,\n",
    "            cv=cv,\n",
    "            scoring=scoring,\n",
    "            refit=\"r2\"\n",
    "        )\n",
    "\n",
    "        grid_multi.fit(loop_X, y_train)\n",
    "        best_index = grid_multi.best_index_\n",
    "\n",
    "        multi_feat_results.append({\n",
    "            \"Feature Set\": set_name,\n",
    "            \"Num Features\": len(features),\n",
    "            \"r2\": grid_multi.cv_results_[\"mean_test_r2\"][best_index],\n",
    "            \"rmse\": abs(grid_multi.cv_results_[\"mean_test_rmse\"][best_index]),\n",
    "            \"mae\": abs(grid_multi.cv_results_[\"mean_test_mae\"][best_index]),\n",
    "            \"fit_intercept\": grid_multi.best_params_[\"fit_intercept\"]\n",
    "        })\n",
    "\n",
    "    results_df = pd.DataFrame(multi_feat_results)\n",
    "    best_row = results_df.sort_values(\"r2\", ascending=False).iloc[0]\n",
    "    best_model_name = \"Multiple Linear Regression\"\n",
    "\n",
    "    return results_df, best_row, best_model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39523b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_polynomial(\n",
    "    X_train_scaled,\n",
    "    y_train,\n",
    "    feature_set=feature_set,\n",
    "    cv=kf,\n",
    "    scoring=scoring\n",
    "):\n",
    "    \"\"\"\n",
    "    Tune Polynomial Regression (interaction-only).\n",
    "    \"\"\"\n",
    "\n",
    "    poly_pipe = make_pipeline(\n",
    "        PolynomialFeatures(interaction_only=True),\n",
    "        LinearRegression()\n",
    "    )\n",
    "\n",
    "    param_grid = {\n",
    "        \"polynomialfeatures__degree\": [1, 2, 3, 4],\n",
    "        \"linearregression__fit_intercept\": [True, False]\n",
    "    }\n",
    "\n",
    "    poly_feat_results = []\n",
    "\n",
    "    for set_name, features in feature_set.items():\n",
    "        loop_X = X_train_scaled[features]\n",
    "\n",
    "        grid_poly = GridSearchCV(\n",
    "            poly_pipe,\n",
    "            param_grid,\n",
    "            cv=cv,\n",
    "            scoring=scoring,\n",
    "            refit=\"r2\",\n",
    "            n_jobs=-1\n",
    "        )\n",
    "\n",
    "        grid_poly.fit(loop_X, y_train)\n",
    "        best_index = grid_poly.best_index_\n",
    "\n",
    "        poly_feat_results.append({\n",
    "            \"Feature Set\": set_name,\n",
    "            \"Num Features\": len(features),\n",
    "            \"Degree\": grid_poly.best_params_[\"polynomialfeatures__degree\"],\n",
    "            \"r2\": grid_poly.cv_results_[\"mean_test_r2\"][best_index],\n",
    "            \"rmse\": abs(grid_poly.cv_results_[\"mean_test_rmse\"][best_index]),\n",
    "            \"mae\": abs(grid_poly.cv_results_[\"mean_test_mae\"][best_index]),\n",
    "        })\n",
    "\n",
    "    results_df = pd.DataFrame(poly_feat_results)\n",
    "    best_row = results_df.sort_values(\"r2\", ascending=False).iloc[0]\n",
    "    best_model_name = f\"Polynomial (deg={best_row['Degree']})\"\n",
    "\n",
    "    return results_df, best_row, best_model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee57271",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models_dict[ridge_label] = {\n",
    "    'model_obj': model_ridge_best,\n",
    "    'features': best_ridge_feats\n",
    "}\n",
    "\n",
    "model_simple\n",
    "model_multi\n",
    "model_poly\n",
    "model_lasso\n",
    "model_ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6247bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_lasso(\n",
    "    X_train_scaled,\n",
    "    y_train,\n",
    "    feature_set=feature_set,\n",
    "    cv=kf,\n",
    "    scoring=scoring,\n",
    "    alpha_grid=None,\n",
    "    random_state=42\n",
    "):\n",
    "    \"\"\"\n",
    "    Tune Lasso Regression over feature sets.\n",
    "    \"\"\"\n",
    "\n",
    "    if alpha_grid is None:\n",
    "        alpha_grid = [0.01, 0.1, 1.0, 10.0]\n",
    "\n",
    "    param_grid = {\n",
    "        \"alpha\": alpha_grid,\n",
    "        \"fit_intercept\": [True, False]\n",
    "    }\n",
    "\n",
    "    lasso_feat_results = []\n",
    "\n",
    "    for set_name, features in feature_set.items():\n",
    "        loop_X = X_train_scaled[features]\n",
    "\n",
    "        grid_lasso = GridSearchCV(\n",
    "            Lasso(random_state=random_state, max_iter=10000),\n",
    "            param_grid,\n",
    "            cv=cv,\n",
    "            scoring=scoring,\n",
    "            refit=\"r2\"\n",
    "        )\n",
    "\n",
    "        grid_lasso.fit(loop_X, y_train)\n",
    "        best_index = grid_lasso.best_index_\n",
    "\n",
    "        lasso_feat_results.append({\n",
    "            \"Feature Set\": set_name,\n",
    "            \"Alpha\": grid_lasso.best_params_[\"alpha\"],\n",
    "            \"r2\": grid_lasso.cv_results_[\"mean_test_r2\"][best_index],\n",
    "            \"rmse\": abs(grid_lasso.cv_results_[\"mean_test_rmse\"][best_index]),\n",
    "            \"mae\": abs(grid_lasso.cv_results_[\"mean_test_mae\"][best_index]),\n",
    "        })\n",
    "\n",
    "    results_df = pd.DataFrame(lasso_feat_results)\n",
    "    best_row = results_df.sort_values(\"r2\", ascending=False).iloc[0]\n",
    "    best_model_name = f\"Lasso (alpha={best_row['Alpha']})\"\n",
    "\n",
    "    return results_df, best_row, best_model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6b4e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "def process_thermal_data(\n",
    "    df: pd.DataFrame,\n",
    "    target_col: str,\n",
    "    f_set: dict,\n",
    "    kf_split,\n",
    "    score_dict: dict\n",
    "):\n",
    "    \"\"\"\n",
    "    Processes a subset of data (Heating / Cooling / Off) through the full\n",
    "    optimization pipeline and returns the best models.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    best_models_dict : dict\n",
    "        Trained final models with selected features\n",
    "    best_scores : list\n",
    "        Best CV scores for each estimator\n",
    "    X_test_scaled : pd.DataFrame\n",
    "        Scaled test features\n",
    "    y_test : pd.Series\n",
    "        Test target values\n",
    "    \"\"\"\n",
    "\n",
    "    # -----------------------------\n",
    "    # 1. Split & scale\n",
    "    # -----------------------------\n",
    "    X = df.drop(columns=[target_col])\n",
    "    y = df[target_col]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = pd.DataFrame(\n",
    "        scaler.fit_transform(X_train),\n",
    "        columns=X.columns,\n",
    "        index=X_train.index\n",
    "    )\n",
    "\n",
    "    X_test_scaled = pd.DataFrame(\n",
    "        scaler.transform(X_test),\n",
    "        columns=X.columns,\n",
    "        index=X_test.index\n",
    "    )\n",
    "\n",
    "    # -----------------------------\n",
    "    # 2. Run all tuning functions\n",
    "    # -----------------------------\n",
    "    best_scores = []\n",
    "    best_models_dict = {}\n",
    "\n",
    "    # --- Simple Linear ---\n",
    "    simple_df, simple_best, simple_name = tune_simple_linear(\n",
    "        X_train_scaled,\n",
    "        y_train,\n",
    "        cv=kf_split,\n",
    "        scoring=score_dict\n",
    "    )\n",
    "\n",
    "    best_scores.append({\n",
    "        \"Model\": simple_name,\n",
    "        \"Feature_set\": simple_best[\"Feature\"],\n",
    "        \"r2\": simple_best[\"r2\"],\n",
    "        \"rmse\": simple_best[\"rmse\"],\n",
    "        \"mae\": simple_best[\"mae\"]\n",
    "    })\n",
    "\n",
    "    model_simple = LinearRegression()\n",
    "    model_simple.fit(\n",
    "        X_train_scaled[[simple_best[\"Feature\"]]],\n",
    "        y_train\n",
    "    )\n",
    "\n",
    "    best_models_dict[\"Simple Linear\"] = {\n",
    "        \"model_obj\": model_simple,\n",
    "        \"features\": [simple_best[\"Feature\"]]\n",
    "    }\n",
    "\n",
    "    # --- Multiple Linear ---\n",
    "    multi_df, multi_best, multi_name = tune_multi_linear(\n",
    "        X_train_scaled,\n",
    "        y_train,\n",
    "        feature_set=f_set,\n",
    "        cv=kf_split,\n",
    "        scoring=score_dict\n",
    "    )\n",
    "\n",
    "    best_scores.append({\n",
    "        \"Model\": multi_name,\n",
    "        \"Feature_set\": multi_best[\"Feature Set\"],\n",
    "        \"r2\": multi_best[\"r2\"],\n",
    "        \"rmse\": multi_best[\"rmse\"],\n",
    "        \"mae\": multi_best[\"mae\"]\n",
    "    })\n",
    "\n",
    "    model_multi = LinearRegression(\n",
    "        fit_intercept=multi_best[\"fit_intercept\"]\n",
    "    )\n",
    "    model_multi.fit(\n",
    "        X_train_scaled[f_set[multi_best[\"Feature Set\"]]],\n",
    "        y_train\n",
    "    )\n",
    "\n",
    "    best_models_dict[\"Multi Linear\"] = {\n",
    "        \"model_obj\": model_multi,\n",
    "        \"features\": f_set[multi_best[\"Feature Set\"]]\n",
    "    }\n",
    "\n",
    "    # --- Polynomial ---\n",
    "    poly_df, poly_best, poly_name = tune_polynomial(\n",
    "        X_train_scaled,\n",
    "        y_train,\n",
    "        feature_set=f_set,\n",
    "        cv=kf_split,\n",
    "        scoring=score_dict\n",
    "    )\n",
    "\n",
    "    best_scores.append({\n",
    "        \"Model\": poly_name,\n",
    "        \"Feature_set\": poly_best[\"Feature Set\"],\n",
    "        \"r2\": poly_best[\"r2\"],\n",
    "        \"rmse\": poly_best[\"rmse\"],\n",
    "        \"mae\": poly_best[\"mae\"]\n",
    "    })\n",
    "\n",
    "    best_models_dict[\"Polynomial\"] = {\n",
    "        \"model_obj\": None,  # pipeline already refit internally\n",
    "        \"features\": f_set[poly_best[\"Feature Set\"]]\n",
    "    }\n",
    "\n",
    "    # --- Lasso ---\n",
    "    lasso_df, lasso_best, lasso_name = tune_lasso(\n",
    "        X_train_scaled,\n",
    "        y_train,\n",
    "        feature_set=f_set,\n",
    "        cv=kf_split,\n",
    "        scoring=score_dict\n",
    "    )\n",
    "\n",
    "    best_scores.append({\n",
    "        \"Model\": lasso_name,\n",
    "        \"Feature_set\": lasso_best[\"Feature Set\"],\n",
    "        \"r2\": lasso_best[\"r2\"],\n",
    "        \"rmse\": lasso_best[\"rmse\"],\n",
    "        \"mae\": lasso_best[\"mae\"]\n",
    "    })\n",
    "\n",
    "    model_lasso = Lasso(\n",
    "        alpha=lasso_best[\"Alpha\"],\n",
    "        max_iter=10000,\n",
    "        random_state=42\n",
    "    )\n",
    "    model_lasso.fit(\n",
    "        X_train_scaled[f_set[lasso_best[\"Feature Set\"]]],\n",
    "        y_train\n",
    "    )\n",
    "\n",
    "    best_models_dict[\"Lasso\"] = {\n",
    "        \"model_obj\": model_lasso,\n",
    "        \"features\": f_set[lasso_best[\"Feature Set\"]]\n",
    "    }\n",
    "\n",
    "    # --- Ridge ---\n",
    "    ridge_df, ridge_best, ridge_name = tune_ridge(\n",
    "        X_train_scaled,\n",
    "        y_train,\n",
    "        feature_set=f_set,\n",
    "        cv=kf_split,\n",
    "        scoring=score_dict\n",
    "    )\n",
    "\n",
    "    best_scores.append({\n",
    "        \"Model\": ridge_name,\n",
    "        \"Feature_set\": ridge_best[\"Feature Set\"],\n",
    "        \"r2\": ridge_best[\"r2\"],\n",
    "        \"rmse\": ridge_best[\"rmse\"],\n",
    "        \"mae\": ridge_best[\"mae\"]\n",
    "    })\n",
    "\n",
    "    model_ridge = Ridge(\n",
    "        alpha=ridge_best[\"Alpha\"],\n",
    "        random_state=42\n",
    "    )\n",
    "    model_ridge.fit(\n",
    "        X_train_scaled[f_set[ridge_best[\"Feature Set\"]]],\n",
    "        y_train\n",
    "    )\n",
    "\n",
    "    best_models_dict[\"Ridge\"] = {\n",
    "        \"model_obj\": model_ridge,\n",
    "        \"features\": f_set[ridge_best[\"Feature Set\"]]\n",
    "    }\n",
    "\n",
    "    # -----------------------------\n",
    "    # 3. Return everything needed downstream\n",
    "    # -----------------------------\n",
    "    return best_models_dict, best_scores, X_test_scaled, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20674a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    best_results.append({\n",
    "        \"Model\": simple_name,\n",
    "        \"Feature_set\": simple_best[\"Feature\"],\n",
    "        \"r2\": simple_best[\"r2\"],\n",
    "        \"rmse\": simple_best[\"rmse\"],\n",
    "        \"mae\": simple_best[\"mae\"]\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e157af71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example for Heating Subset\n",
    "rf_df_h, rf_best_h, rf_model_h = tune_rf(X_train_heat_scaled, y_train_heat, feature_set, kf, scoring)\n",
    "gb_df_h, gb_best_h, gb_model_h = tune_gb(X_train_heat_scaled, y_train_heat, feature_set, kf, scoring)\n",
    "\n",
    "best_models_dict[\"Optimized Random Forest (Heating)\"] = {\n",
    "    \"model_obj\": rf_model_h,\n",
    "    \"features\": feature_set[rf_best_h[\"Feature Set\"]],\n",
    "    \"is_optimized\": True\n",
    "}\n",
    "\n",
    "best_models_dict[\"Optimized Gradient Boosting (Heating)\"] = {\n",
    "    \"model_obj\": gb_model_h,\n",
    "    \"features\": feature_set[gb_best_h[\"Feature Set\"]],\n",
    "    \"is_optimized\": True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1b9c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = []\n",
    "\n",
    "for name, info in best_models_dict.items():\n",
    "    model = info['model_obj']\n",
    "    feats = info['features']\n",
    "\n",
    "    # 1. Select the correct X_test data source\n",
    "    if info.get('is_optimized') == True:\n",
    "        X_test_input = X_test_opt_scaled\n",
    "    else:\n",
    "        X_test_input = X_test_scaled\n",
    "\n",
    "    # 2. Prepare the features for prediction\n",
    "    # Logic for Baseline Polynomial (requires expansion)\n",
    "    if info.get('is_poly_baseline') == True:\n",
    "        data_to_predict = poly.transform(X_test_input[feats])\n",
    "    # Logic for all other models (Standard Linear, Trees, etc.)\n",
    "    else:\n",
    "        data_to_predict = X_test_input[feats]\n",
    "\n",
    "    # 3. Predict on the TEST set\n",
    "    y_pred = model.predict(data_to_predict)\n",
    "\n",
    "    # 4. Calculate metrics\n",
    "    test_results.append({\n",
    "        \"Model\": name,\n",
    "        \"Optimized\": info.get('is_optimized'),\n",
    "        \"R2\": r2_score(y_test_opt, y_pred),\n",
    "        \"RMSE\": np.sqrt(mean_squared_error(y_test_opt, y_pred)),\n",
    "        \"MAE\": mean_absolute_error(y_test_opt, y_pred)\n",
    "    })\n",
    "\n",
    "# Convert to DataFrame and sort\n",
    "test_results_df = (\n",
    "    pd.DataFrame(test_results)\n",
    "    .sort_values(\"R2\", ascending=False)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "test_results_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.14.0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
